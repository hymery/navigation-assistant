<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>–ù–∞–≤–∏–≥–∞—Ü–∏–æ–Ω–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫</title>
    <script src="https://telegram.org/js/telegram-web-app.js"></script>
    <style>
        * { 
            margin: 0; 
            padding: 0; 
            box-sizing: border-box; 
        }
        body { 
            font-family: Arial, sans-serif; 
            background: #000000; 
            color: #ffffff; 
            height: 100vh;
            display: flex;
            flex-direction: column;
        }
        
        .header {
            background: #000000;
            padding: 20px;
            text-align: center;
            border-bottom: 3px solid #00ff00;
        }
        
        h1 {
            color: #00ff00;
            font-size: 28px;
            font-weight: bold;
        }
        
        .video-container {
            flex: 1;
            background: #000000;
            display: flex;
            align-items: center;
            justify-content: center;
            border: 4px solid #00ff00;
            margin: 10px;
        }
        
        #webcam {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        
        .controls {
            padding: 20px;
            background: #000000;
        }
        
        .main-btn {
            width: 100%;
            padding: 25px;
            background: #00ff00;
            color: #000000;
            border: none;
            border-radius: 0;
            font-size: 24px;
            font-weight: bold;
            cursor: pointer;
        }
        
        .main-btn:disabled {
            background: #666666;
            color: #cccccc;
            cursor: not-allowed;
        }
        
        .status {
            background: #00ff00;
            color: #000000;
            padding: 15px;
            text-align: center;
            font-size: 18px;
            font-weight: bold;
        }
        
        .warning {
            background: #ff0000;
            color: #ffffff;
            padding: 20px;
            text-align: center;
            font-size: 20px;
            font-weight: bold;
            display: none;
        }

        .speaking-indicator {
            background: #0066ff;
            color: #ffffff;
            padding: 10px;
            text-align: center;
            font-size: 16px;
            display: none;
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>üß≠ –ù–ê–í–ò–ì–ê–¶–ò–û–ù–ù–´–ô –ü–û–ú–û–©–ù–ò–ö</h1>
    </div>
    
    <div class="video-container">
        <video id="webcam" autoplay playsinline muted></video>
    </div>
    
    <div class="controls">
        <button class="main-btn" id="mainBtn" disabled>–ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ò...</button>
    </div>
    
    <div class="status" id="status">–ó–∞–≥—Ä—É–∑–∫–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏...</div>
    
    <div class="warning" id="warning"></div>

    <div class="speaking-indicator" id="speakingIndicator">
        üó£Ô∏è –û–∑–≤—É—á–∏–≤–∞—é –æ–∫—Ä—É–∂–µ–Ω–∏–µ...
    </div>

    <audio id="audioPlayer" style="display: none;"></audio>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@2.2.2/dist/coco-ssd.min.js"></script>
    
    <script>
        // ==================== –°–ò–°–¢–ï–ú–ê –û–ó–í–£–ß–ö–ò ====================
        class SpeechSynthesizer {
            constructor() {
                this.isSpeaking = false;
                this.audioContext = null;
                this.audioPlayer = document.getElementById('audioPlayer');
                this.speakingIndicator = document.getElementById('speakingIndicator');
            }

            getSpeechKitConfig() {
                return {
                    apiUrl: 'https://tts.api.cloud.yandex.net/speech/v1/tts:synthesize',
                    folderId: 'b1gj8glojqbh843o2iq5',
                    iamToken: 'ajenblfsa0oup3hjtv7i'
                };
            }

getVoiceSettings() {
                return {
                    voice: 'alena',
                    emotion: 'good',
                    speed: '0.9',
                    format: 'lpcm',
                    sampleRate: 48000
                };
            }

            distanceToText(distance) {
                if (distance < 1) return "–æ—á–µ–Ω—å –±–ª–∏–∑–∫–æ";
                if (distance < 2) return "–±–ª–∏–∑–∫–æ";
                if (distance < 4) return "–Ω–µ–¥–∞–ª–µ–∫–æ";
                if (distance < 8) return "–≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–µ—Ç—Ä–∞—Ö";
                return "–¥–∞–ª–µ–∫–æ";
            }

            generateDetectionSpeech(detections) {
                if (!detections || detections.length === 0) {
                    return "–û–±—ä–µ–∫—Ç—ã –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã. –ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –¥–≤–∏–∂–µ–Ω–∏–µ –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ.";
                }

                const sortedDetections = [...detections].sort((a, b) => {
                    const areaA = a.bbox[2] * a.bbox[3];
                    const areaB = b.bbox[2] * b.bbox[3];
                    return areaB - areaA;
                });

                let speechText = "";
                const nearestObjects = sortedDetections.slice(0, 3);

                const getRelativeDistance = (bbox) => {
                    const area = bbox[2] * bbox[3];
                    const screenArea = window.innerWidth * window.innerHeight;
                    const ratio = area / screenArea;
                    
                    if (ratio > 0.3) return 0.5;
                    if (ratio > 0.15) return 1.0;
                    if (ratio > 0.05) return 2.5;
                    return 5.0;
                };

                if (nearestObjects.length > 0) {
                    const nearest = nearestObjects[0];
                    const distance = getRelativeDistance(nearest.bbox);
                    
                    speechText += –í–ø–µ—Ä–µ–¥–∏ ${nearest.class}. ;
                    speechText += –ù–∞—Ö–æ–¥–∏—Ç—Å—è ${this.distanceToText(distance)}. ;

                    const dangerousObjects = ['person', 'car', 'bicycle', 'motorcycle', 'fire hydrant', 'stop sign'];
                    if (dangerousObjects.includes(nearest.class) && distance < 2) {
                        speechText += "–í–Ω–∏–º–∞–Ω–∏–µ! –ë—É–¥—å—Ç–µ –æ—Å—Ç–æ—Ä–æ–∂–Ω—ã. ";
                    }
                }

                if (nearestObjects.length > 1) {
                    const otherObjects = nearestObjects.slice(1, 3);
                    if (otherObjects.length > 0) {
                        speechText += "–¢–∞–∫–∂–µ —Ä—è–¥–æ–º: ";
                        otherObjects.forEach((obj, index) => {
                            const distance = getRelativeDistance(obj.bbox);
                            speechText += ${obj.class} ${this.distanceToText(distance)};
                            if (index < otherObjects.length - 1) speechText += ", ";
                        });
                        speechText += ". ";
                    }
                }

                if (detections.length > 3) {
                    speechText += –í—Å–µ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ ${detections.length} –æ–±—ä–µ–∫—Ç–æ–≤. ;
                }

                speechText += "–ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –¥–≤–∏–∂–µ–Ω–∏–µ –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ.";
                return speechText;
            }

            async speakDetectionResults(detections) {
                if (this.isSpeaking) return;

                this.isSpeaking = true;
                this.showSpeakingIndicator(true);

                try {
                    const speechText = this.generateDetectionSpeech(detections);
                    console.log("–û–∑–≤—É—á–∏–≤–∞–µ–º:", speechText);
                    await this.synthesizeAndPlay(speechText);
                    
                } catch (error) {
                    console.error('Speech synthesis error:', error);
                } finally {
                    this.isSpeaking = false;
                    this.showSpeakingIndicator(false);
                }
            }

            async synthesizeAndPlay(text) {
                const config = this.getSpeechKitConfig();
                const voiceSettings = this.getVoiceSettings();

const response = await fetch(config.apiUrl, {
                    method: 'POST',
                    headers: {
                        'Authorization': Bearer ${config.iamToken},
                        'Content-Type': 'application/x-www-form-urlencoded'
                    },
                    body: new URLSearchParams({
                        'text': text,
                        'voice': voiceSettings.voice,
                        'emotion': voiceSettings.emotion,
                        'speed': voiceSettings.speed,
                        'folderId': config.folderId,
                        'format': 'lpcm',
                        'sampleRateHertz': '48000'
                    })
                });

                if (!response.ok) {
                    throw new Error(SpeechKit error: ${response.status});
                }

                const audioData = await response.arrayBuffer();
                const wavBuffer = this.convertToWav(audioData);
                const audioUrl = URL.createObjectURL(new Blob([wavBuffer], { type: 'audio/wav' }));
                
                this.audioPlayer.src = audioUrl;
                
                await this.audioPlayer.play();
                await new Promise((resolve) => {
                    this.audioPlayer.onended = resolve;
                });
            }

            convertToWav(audioData) {
                const buffer = new ArrayBuffer(44 + audioData.byteLength);
                const view = new DataView(buffer);
                
                this.writeString(view, 0, 'RIFF');
                view.setUint32(4, 36 + audioData.byteLength, true);
                this.writeString(view, 8, 'WAVE');
                this.writeString(view, 12, 'fmt ');
                view.setUint32(16, 16, true);
                view.setUint16(20, 1, true);
                view.setUint16(22, 1, true);
                view.setUint32(24, 48000, true);
                view.setUint32(28, 48000 * 2, true);
                view.setUint16(32, 2, true);
                view.setUint16(34, 16, true);
                this.writeString(view, 36, 'data');
                view.setUint32(40, audioData.byteLength, true);
                
                const audioBytes = new Uint8Array(audioData);
                const wavBytes = new Uint8Array(buffer);
                wavBytes.set(audioBytes, 44);
                
                return buffer;
            }

            writeString(view, offset, string) {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            }

            showSpeakingIndicator(show) {
                this.speakingIndicator.style.display = show ? 'block' : 'none';
            }

            async speakEmergency(message) {
                if (this.isSpeaking) {
                    this.audioPlayer.pause();
                    this.isSpeaking = false;
                }
                await this.synthesizeAndPlay("–í–Ω–∏–º–∞–Ω–∏–µ! " + message);
            }
        }

        // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –æ–∑–≤—É—á–∫–∏
        let speechSynthesizer;
        Telegram.WebApp.ready();
        Telegram.WebApp.expand();
        speechSynthesizer = new SpeechSynthesizer();
        window.speechSynthesizer = speechSynthesizer;
        console.log("‚úÖ –°–∏—Å—Ç–µ–º–∞ –æ–∑–≤—É—á–∫–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞");
    </script>

    <script src="app.js"></script>
</body>
</html>

